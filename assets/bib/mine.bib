
@inproceedings{beyer_can_2017,
  address = {Prague, Czech Republic},
  title = {Can {Out}-of-the-box {NMT} {Beat} a {Domain}-trained {Moses} on {Technical} {Data}?},
  url_Paper = {https://ufal.mff.cuni.cz/eamt2017/user-project-product-papers/papers/user/EAMT2017_paper_32.pdf},
  abstract = {In the last year, we have seen a lot of evidence about the superiority of neural machine translation approaches (NMT) over phrase-based statistical approaches (PBMT). This trend has shown for the general domain at public competitions such as the WMT challenges as well as in the obvious quality increase in online translation services that have changed their technology. In this paper, we take the perspective of an LSP. The questions we want to answer with this study is if now is already the time to invest in the new technology. To answer this question, we have collected evidence as to whether an existing stateof-the-art NMT system for the general domain can already compete with a domaintrained and optimised Moses (PBMT) system or if it is maybe already better. As it is well known that automatic quality measures are not reliable for comparing the performance of different system types, we have performed a detailed manual evaluation based on a test suite of domain segments.},
  language = {en},
  booktitle = {Proceedings for {EAMT} 2017 {User} {Studies} and {Project}/{Product} {Descriptions}},
  author = {Beyer, Anne and Macketanz, Vivien and Burchardt, Aljoscha and Williams, Philip},
  year = {2017},
  pages = {41--46}
}

@inproceedings{beyer_embedding_2020,
  author    = {Beyer, Anne  and  Kauermann, Göran  and  Schütze, Hinrich},
  title     = {Embedding Space Correlation as a Measure of Domain Similarity},
  booktitle = {Proceedings of The 12th Language Resources and Evaluation Conference},
  year      = {2020},
  address   = {Marseille, France},
  pages     = {2431--2439},
  abstract  = {Prior work has determined domain similarity using text-based features of a corpus. However, when using pre-trained word embeddings, the underlying text corpus might not be accessible anymore. Therefore, we propose the CCA measure, a new measure of domain similarity based directly on the dimension-wise correlations between corresponding embedding spaces. Our results suggest that an inherent notion of domain can be captured this way, as we are able to reproduce our findings for different domain comparisons for English, German, Spanish and Czech as well as in cross-lingual comparisons. We further find a threshold at which the CCA measure indicates that two corpora come from the same domain in a monolingual setting by applying permutation tests. By evaluating the usability of the CCA measure in a domain adaptation application, we also show that it can be used to determine which corpora are more similar to each other in a cross-domain sentiment detection task.},
  url_Paper = {https://www.aclweb.org/anthology/2020.lrec-1.296.pdf}
}

@inproceedings{beyer_incoherence_2021,
    author = {Beyer, Anne and Lo\'aiciga, Sharid and Schlangen, David},
    year = {2021},
    title = {Is {Incoherence} {Surprising}? {Targeted} {Evaluation} of {Coherence} {Prediction} from {Language} {Models}},
    abstract = {Coherent discourse is distinguished from a mere collection of utterances by the satisfaction of a diverse set of constraints, for example choice of expression, logical relation between denoted events, and implicit compatibility with world-knowledge. Do neural language models encode such constraints? We design an extendable set of test suites addressing different aspects of discourse and dialogue coherence. Unlike most previous coherence evaluation studies, we address specific linguistic devices beyond sentence order perturbations, allowing for a more fine-grained analysis of what constitutes coherence and what neural models trained on a language modelling objective do encode. Extending the targeted evaluation paradigm for neural language models (Marvin and Linzen, 2018) to phenomena beyond syntax, we show that this paradigm is equally suited to evaluate linguistic qualities that contribute to the notion of coherence.},
    booktitle = {Proceedings of the 2021 {Conference} of the {North} {A}merican {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
    publisher = {Association for {Computational} {Linguistics}},
    url_Paper = {https://arxiv.org/pdf/2105.03495.pdf},
    address = {Online}
}
