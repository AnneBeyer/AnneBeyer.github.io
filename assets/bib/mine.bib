
@inproceedings{beyer_can_2017,
	address = {Prague, Czech Republic},
	title = {Can {Out}-of-the-box {NMT} {Beat} a {Domain}-trained {Moses} on {Technical} {Data}?},
	url_Paper = {https://ufal.mff.cuni.cz/eamt2017/user-project-product-papers/papers/user/EAMT2017_paper_32.pdf},
	abstract = {In the last year, we have seen a lot of evidence about the superiority of neural machine translation approaches (NMT) over phrase-based statistical approaches (PBMT). This trend has shown for the general domain at public competitions such as the WMT challenges as well as in the obvious quality increase in online translation services that have changed their technology. In this paper, we take the perspective of an LSP. The questions we want to answer with this study is if now is already the time to invest in the new technology. To answer this question, we have collected evidence as to whether an existing stateof-the-art NMT system for the general domain can already compete with a domaintrained and optimised Moses (PBMT) system or if it is maybe already better. As it is well known that automatic quality measures are not reliable for comparing the performance of different system types, we have performed a detailed manual evaluation based on a test suite of domain segments.},
	language = {en},
	booktitle = {Proceedings for {EAMT} 2017 {User} {Studies} and {Project}/{Product} {Descriptions}},
	author = {Beyer, Anne and Macketanz, Vivien and Burchardt, Aljoscha and Williams, Philip},
	year = {2017},
	pages = {41--46}
}

@inproceedings{beyer_measuring_2020,
	title = {Measuring {Domain} {Similarity} {Based} on {Embedding} {Spaces}},
	booktitle = {To be published in {Proceedings} of {LREC}},
	author = {Beyer, Anne and Kauermann, Göran and Schütze, Hinrich},
	year = {2020}
}

@inproceedings{zarries_know_2019,
	address = {Florence, Italy},
	title = {Know {What} {You} {Don}'t {Know}: {Modeling} a {Pragmatic} {Speaker} that {Refers} to {Objects} of {Unknown} {Categories}},
	url = {https://www.aclweb.org/anthology/P19-1063},
	abstract = {Zero-shot learning in Language \& Vision is the task of correctly labelling (or naming) objects of novel categories. Another strand of work in L\&V aims at pragmatically informative rather than “correct” object descriptions, e.g. in reference games. We combine these lines of research and model zero-shot reference games, where a speaker needs to successfully refer to a novel object in an image. Inspired by models of “rational speech acts”, we extend a neural generator to become a pragmatic speaker reasoning about uncertain object categories. As a result of this reasoning, the generator produces fewer nouns and names of distractor categories as compared to a literal speaker. We show that this conversational strategy for dealing with novel objects often improves communicative success, in terms of resolution accuracy of an automatic listener.},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Zarrieß, Sina and Schlangen, David},
	month = jul,
	year = {2019},
	pages = {654--659}
}

@article{galetzka_corpus_2020,
	title = {A {Corpus} of {Controlled} {Opinionated} and {Knowledgeable} {Movie} {Discussions} for {Training} {Neural} {Conversation} {Models}},
	url = {http://arxiv.org/abs/2003.13342},
	abstract = {Fully data driven Chatbots for non-goal oriented dialogues are known to suffer from inconsistent behaviour across their turns, stemming from a general difﬁculty in controlling parameters like their assumed background personality and knowledge of facts. One reason for this is the relative lack of labeled data from which personality consistency and fact usage could be learned together with dialogue behaviour. To address this, we introduce a new labeled dialogue dataset in the domain of movie discussions, where every dialogue is based on pre-speciﬁed facts and opinions. We thoroughly validate the collected dialogue for adherence of the participants to their given fact and opinion proﬁle, and ﬁnd that the general quality in this respect is high. This process also gives us an additional layer of annotation that is potentially useful for training models. We introduce as a baseline an end-to-end trained self-attention decoder model trained on this data and show that it is able to generate opinionated responses that are judged to be natural and knowledgeable and show attentiveness.},
	journal = {arXiv:2003.13342 [cs]},
	author = {Galetzka, Fabian and Eneh, Chukwuemeka U. and Schlangen, David},
	year = {2020},
	annote = {Comment: 8 Pages, 8 Figures, 5 Tables. Accepted paper for LREC 2020 conference}
}
